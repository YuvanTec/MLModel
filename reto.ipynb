{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"RETO.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/19TGALxak7pBVG38SZ6O3K1unNczVjQl6\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carga el archivo desde tu Google Drive o s√∫belo directamente en Colab\n",
    "file_path = '/Users/yuvan/Downloads/Data 80 aniversario study QS.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df.head()\n",
    "\n",
    "# Renombramos la columna objetivo para facilitar el trabajo\n",
    "df = df.rename(columns={\n",
    "    'Since graduating from Tecnol√≥gico de Monterrey, have you founded a nonprofit organization, as part of the founding group or main founder?': 'founded_nonprofit'\n",
    "})\n",
    "\n",
    "# Ver las respuestas √∫nicas\n",
    "print(df['founded_nonprofit'].unique())\n",
    "\n",
    "# Codificaci√≥n binaria\n",
    "df['founded_nonprofit_bin'] = df['founded_nonprofit'].map({\n",
    "    'Yes': 1,\n",
    "    'No': 0\n",
    "})\n",
    "\n",
    "label_col = df['founded_nonprofit_bin']\n",
    "\n",
    "# Drop columns with more than 70% missing values\n",
    "threshold = 0.7\n",
    "df_reduced = df.loc[:, df.isnull().mean() < threshold]\n",
    "df = df_reduced.copy()\n",
    "\n",
    "low_variance_cols = [col for col in df.columns if df[col].nunique(dropna=True) <= 1]\n",
    "df = df.drop(columns=low_variance_cols)\n",
    "df = df.drop(columns=['External Data Reference'])\n",
    "\n",
    "# Separate numerical and categorical\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check uniqueness\n",
    "for col in num_cols:\n",
    "    unique_vals = df[col].nunique()\n",
    "    print(f\"{col}: {unique_vals} unique values\")\n",
    "    if unique_vals > 10 and unique_vals < 100:\n",
    "        df[col].hist(bins=20)\n",
    "        plt.title(col)\n",
    "        plt.show()\n",
    "\n",
    "df['AGE_bucket'] = pd.cut(df['AGE'], bins=[17, 29, 39, 49, 59, 120], labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "def scholarship_bucket(x):\n",
    "    if pd.isna(x):\n",
    "        return 'Missing'\n",
    "    elif x == 0:\n",
    "        return 0\n",
    "    elif x <= 25:\n",
    "        return 1\n",
    "    elif x <= 50:\n",
    "        return 2\n",
    "    elif x <= 75:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "df['scholarship_bucket'] = df['What percentage of support did you receive from the scholarship?'].apply(scholarship_bucket)\n",
    "\n",
    "df['work_hours_bucket'] = pd.cut(df['How many hours do you usually work per week?'],\n",
    "                                 bins=[0, 20, 39, 49, 60, 100],\n",
    "                                 labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "df['donation_hours_bucket'] = pd.cut(df['Would you please share an estimate amount of how many hours per MONTH you donate to social organizations?  hours per month'],\n",
    "                                     bins=[-1, 0, 4, 10, 20, 100],\n",
    "                                     labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "# Define Likert bucketing function\n",
    "def bucket_likert(val):\n",
    "    if pd.isna(val):\n",
    "        return 0\n",
    "    elif val <= 4:\n",
    "        return 1\n",
    "    elif val <= 7:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# List of Likert-scale columns\n",
    "likert_cols = [\n",
    "    col for col in df.columns\n",
    "    if col.startswith('Please rate each') or col.startswith('Please rate each of the following')\n",
    "]\n",
    "\n",
    "\n",
    "# Apply bucketing\n",
    "for col in likert_cols:\n",
    "    new_col = col + ' (bucketed)'\n",
    "    df[new_col] = df[col].apply(bucket_likert)\n",
    "    print(str(df[new_col]))\n",
    "\n",
    "# List of raw numeric columns used for bucketing\n",
    "raw_numeric_bucket_cols = [\n",
    "    'AGE',\n",
    "    'What percentage of support did you receive from the scholarship?',\n",
    "    'How many hours do you usually work per week?',\n",
    "    'Would you please share an estimate amount of how many hours per MONTH you donate to social organizations?  hours per month'\n",
    "]\n",
    "\n",
    "# List of original Likert-scale columns\n",
    "likert_raw_cols = [\n",
    "    col for col in df.columns\n",
    "    if (col.startswith('Please rate each') or col.startswith('Please rate each of the following'))\n",
    "    and not '(bucketed)' in col\n",
    "]\n",
    "\n",
    "# Combine and drop from df_model\n",
    "cols_to_drop = raw_numeric_bucket_cols + likert_raw_cols\n",
    "\n",
    "df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "\n",
    "for col in df.columns:\n",
    "  if '(bucketed)' in col and 'rate' in col:\n",
    "    print(df[col])\n",
    "\n",
    "# Separate columns by type\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "for target in ['founded_nonprofit', 'founded_nonprofit_bin']:\n",
    "    if target in cat_cols: cat_cols.remove(target)\n",
    "    if target in num_cols: num_cols.remove(target)\n",
    "\n",
    "# Encode categorical features for df_model_encoded\n",
    "df_encoded = pd.get_dummies(df[cat_cols], drop_first=False)\n",
    "df_model_encoded = pd.concat([df[num_cols], df_encoded], axis=1)\n",
    "\n",
    "# Add back target\n",
    "df_model_encoded['founded_nonprofit_bin'] = label_col\n",
    "\n",
    "# ‚úÖ Optional: check which High-level features are present\n",
    "print(\"\\nüîç Bucketed High features present:\")\n",
    "for col in df_encoded.columns:\n",
    "    if '(bucketed)_High' in col:\n",
    "        print(col)\n",
    "\n",
    "print(df_encoded.columns)\n",
    "\n",
    "my_correlations = df_model_encoded.corr()['founded_nonprofit_bin'].sort_values(ascending=False)\n",
    "correlation_dict = my_correlations.to_dict()\n",
    "\n",
    "for feature, corr_value in sorted(correlation_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{feature}: {corr_value:.4f}\")\n",
    "\n",
    "# Remove low variance features\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "X_reduced = selector.fit_transform(df_model_encoded.drop(columns=[\"founded_nonprofit_bin\"]))\n",
    "selected_columns = df_model_encoded.drop(columns=[\"founded_nonprofit_bin\"]).columns[selector.get_support()]\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "X = df_model_encoded[selected_columns]\n",
    "y = df_model_encoded['founded_nonprofit_bin']  # your yes/no column\n",
    "\n",
    "selector = SelectKBest(chi2, k=10)  # or 'all' to rank everything\n",
    "X_new = selector.fit_transform(X, y)\n",
    "top_features = X.columns[selector.get_support()]\n",
    "print(top_features)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Fit the model\n",
    "model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Create a dictionary of feature -> importance\n",
    "feature_importance_dict = dict(zip(X.columns, importances))\n",
    "\n",
    "# Sort by importance descending\n",
    "sorted_importances = sorted(feature_importance_dict.items(), key=lambda x: -x[1])\n",
    "\n",
    "# Pretty print the results\n",
    "for feature, importance in sorted_importances:\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Try a range of class weights for class 1\n",
    "weights_to_try = [1, 2, 5, 10, 20, 50,75,100,150]\n",
    "results = []\n",
    "\n",
    "for w in weights_to_try:\n",
    "    model = RandomForestClassifier(class_weight={0: 1, 1: w}, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred, pos_label=1)\n",
    "    results.append((w, f1))\n",
    "\n",
    "# Show results\n",
    "for weight, f1 in results:\n",
    "    print(f\"class_weight 1:{weight} ‚Üí F1-score (class 1): {f1:.4f}\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Train model with chosen class_weight\n",
    "model = RandomForestClassifier(class_weight={0: 1, 1: 50}, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Predict probabilities\n",
    "y_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 4. Search for best thresholds\n",
    "thresholds = np.linspace(0.1, 0.9, 81)\n",
    "\n",
    "best_f1_class1 = 0\n",
    "best_f1_macro = 0\n",
    "best_thresh_class1 = 0.5\n",
    "best_thresh_macro = 0.5\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = (y_proba > t).astype(int)\n",
    "\n",
    "    # F1 for positive class\n",
    "    f1_pos = f1_score(y_val, y_pred, pos_label=1)\n",
    "    if f1_pos > best_f1_class1:\n",
    "        best_f1_class1 = f1_pos\n",
    "        best_thresh_class1 = t\n",
    "\n",
    "    # F1 macro (overall)\n",
    "    f1_macro = f1_score(y_val, y_pred, average='macro')\n",
    "    if f1_macro > best_f1_macro:\n",
    "        best_f1_macro = f1_macro\n",
    "        best_thresh_macro = t\n",
    "\n",
    "# 5. Evaluate at best threshold for class 1\n",
    "print(f\"\\n‚úÖ Best Threshold for Class 1 F1: {best_thresh_class1:.2f} ‚Üí F1: {best_f1_class1:.4f}\\n\")\n",
    "y_pred_class1 = (y_proba > best_thresh_class1).astype(int)\n",
    "print(classification_report(y_val, y_pred_class1))\n",
    "print(confusion_matrix(y_val, y_pred_class1))\n",
    "\n",
    "# 6. Evaluate at best threshold for macro F1\n",
    "print(f\"\\n‚úÖ Best Threshold for Macro F1: {best_thresh_macro:.2f} ‚Üí Macro F1: {best_f1_macro:.4f}\\n\")\n",
    "y_pred_macro = (y_proba > best_thresh_macro).astype(int)\n",
    "print(classification_report(y_val, y_pred_macro))\n",
    "print(confusion_matrix(y_val, y_pred_macro))\n",
    "\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-2, 10.0, log=True),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 10, 100),\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"verbose\": 0\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    score = cross_val_score(model, X, y, cv=3, scoring=\"f1\").mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 1. Get best params from Optuna and finalize model\n",
    "best_params = study.best_params\n",
    "best_params[\"loss_function\"] = \"Logloss\"\n",
    "best_params[\"verbose\"] = 0\n",
    "\n",
    "# 2. Train final CatBoost model on training set\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Predict probabilities on validation set\n",
    "y_proba = final_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 4. Search for best thresholds\n",
    "thresholds = np.linspace(0.1, 0.9, 81)\n",
    "\n",
    "best_f1_class1 = 0\n",
    "best_f1_macro = 0\n",
    "best_thresh_class1 = 0.5\n",
    "best_thresh_macro = 0.5\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = (y_proba > t).astype(int)\n",
    "\n",
    "    f1_pos = f1_score(y_val, y_pred, pos_label=1)\n",
    "    if f1_pos > best_f1_class1:\n",
    "        best_f1_class1 = f1_pos\n",
    "        best_thresh_class1 = t\n",
    "\n",
    "    f1_macro = f1_score(y_val, y_pred, average='macro')\n",
    "    if f1_macro > best_f1_macro:\n",
    "        best_f1_macro = f1_macro\n",
    "        best_thresh_macro = t\n",
    "\n",
    "# 5. Print evaluation for best F1 on class 1\n",
    "y_pred_class1 = (y_proba > best_thresh_class1).astype(int)\n",
    "print(f\"\\n‚úÖ Best Threshold for Class 1 F1: {best_thresh_class1:.2f} ‚Üí F1: {best_f1_class1:.4f}\\n\")\n",
    "print(classification_report(y_val, y_pred_class1))\n",
    "print(confusion_matrix(y_val, y_pred_class1))\n",
    "\n",
    "# 6. Print evaluation for best macro F1\n",
    "y_pred_macro = (y_proba > best_thresh_macro).astype(int)\n",
    "print(f\"\\n‚úÖ Best Threshold for Macro F1: {best_thresh_macro:.2f} ‚Üí Macro F1: {best_f1_macro:.4f}\\n\")\n",
    "print(classification_report(y_val, y_pred_macro))\n",
    "print(confusion_matrix(y_val, y_pred_macro))\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "df_filtered.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Define X and y\n",
    "X_notencoded = df_filtered.drop(columns=['founded_nonprofit_bin'])\n",
    "y_notencoded = df_filtered['founded_nonprofit_bin']\n",
    "\n",
    "# Split\n",
    "X_train_notencoded, X_test_notencoded, y_train_notencoded, y_test_notencoded = train_test_split(X_notencoded, y_notencoded, stratify=y_notencoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train CatBoost with categorical columns\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    scale_pos_weight=30,  # or try 10 or 8\n",
    "    cat_features=[col for col in selected_cols if col != 'founded_nonprofit_bin'],\n",
    "    eval_metric='F1',\n",
    "    verbose=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_notencoded, y_train_notencoded)\n",
    "\n",
    "# Predict probabilities\n",
    "y_proba_notencoded = model.predict_proba(X_test_notencoded)[:, 1]\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "# Threshold tuning: precision/recall trade-off\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_notencoded, y_proba_notencoded)\n",
    "for p, r, t in zip(precision, recall, thresholds):\n",
    "    if r > 0.7:\n",
    "        print(f\"Threshold: {t:.2f} | Precision: {p:.2f}, Recall: {r:.2f}\")\n",
    "        break\n",
    "\n",
    "# Choose best threshold\n",
    "best_threshold = 0.85\n",
    "y_pred = (y_proba_notencoded >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_notencoded, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_notencoded, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test_notencoded, y_proba_notencoded))\n",
    "\n",
    "# Optional: plot precision-recall vs. threshold\n",
    "plt.plot(thresholds, precision[:-1], label=\"Precision\")\n",
    "plt.plot(thresholds, recall[:-1], label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision and Recall vs. Threshold\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define X and y\n",
    "X = df_model_encoded.drop(columns=['founded_nonprofit_bin'])\n",
    "y = df_model_encoded['founded_nonprofit_bin']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Feature importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(importances.head(20))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "importances.head(20).plot(kind='barh')\n",
    "plt.gca().invert_yaxis()  # So the most important feature is on top\n",
    "plt.title(\"Top 20 Most Important Features\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
    "\n",
    "# Predict probabilities\n",
    "y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# AUC score\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "# ROC Curve\n",
    "RocCurveDisplay.from_predictions(y_test, y_proba)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate precision-recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Find threshold that gives you at least, say, 70% recall\n",
    "for p, r, t in zip(precision, recall, thresholds):\n",
    "    if r > 0.7:\n",
    "        print(f\"Threshold: {t:.2f} | Precision: {p:.2f}, Recall: {r:.2f}\")\n",
    "        break\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(thresholds, precision[:-1], label=\"Precision\")\n",
    "plt.plot(thresholds, recall[:-1], label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision-Recall vs. Threshold\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "best_threshold = 0.25  # or pick based on visual balance\n",
    "y_pred_custom = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred_custom))\n",
    "print(confusion_matrix(y_test, y_pred_custom))\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(importances.head(30))\n",
    "\n",
    "# prompt: print col names in df_model using for loop\n",
    "\n",
    "for col in df_model_encoded.columns:\n",
    "  print(col)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train.astype(float), y_train.astype(float))\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(scale_pos_weight=8, use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "# Predict probabilities for ROC / threshold tuning\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Predict class labels using default threshold (0.5)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "best_threshold = 0.35\n",
    "y_pred_custom = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred_custom))\n",
    "print(confusion_matrix(y_test, y_pred_custom))\n",
    "\n",
    "df_model_encoded.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
